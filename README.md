# Nikita Voronov

## Basic info                 
**Mobile:** 89201424696            
**GMAIL:** nekitos199@gmail.com            
**Github:** https://github.com/K7chyp            
**LinkdIn:** https://www.linkedin.com/in/nikita-voronov-55ba53206                      
**HH:** https://hh.ru/resume/a365e1feff0b1bfed20039ed1f524d52736f41            
**Telegram:** @nikitaworonov            
**Location:** Moscow             
**Prefer position:** Data Engineer (Hybrid/Remote/Relocate)

## Hard Skills
**Python**           
MLStack (pandas, pyspark, numpy, scipy, sklearn, seaborn, matplotlib, XGBoost, Catboost)           
DLStack (Pytorch, nltk, gensim)           
Other (Kafka, Pytest, Tkinter, Selenium, BeautifulSoup, Tableau, Superset)           
**DB**
SQL (clickhouse, vertica, mysql, memsql, postgresql, sqlite3)           
**Architecture**
Data Vault 2.0, Anchor Modeling, HNHM etc           
**Other**
Git, ci/cd, trello, slack, unix, docker, airflow, jira, outlook, confluence           
## Soft Skills
Communication Skills           
Leadership           
Teamwork            
Emotional Intelligence           


## Experience 
**Data Engineer**           
Delimobil | 2023 August - Present           
As a Data Engineer, I help team of analytics with their scripts - refactoring, updating, speed boosting of execution and etc. and educating. I connect different new sources from backend (api, other bd ) to whole DWH combining them into a common structure using Data Vault 2.0. I write own scripts for changing backend data manipulation               

**Data Engineer**           
IVI | 2021 June - 2023 August           
As a Data Engineer, I worked with different media content estimate products. I updated many data ETL pipelines and processes it connected (logging, transformation). I helped analytics team with their scripts - review, refactoring etc. I setted up ETL piplines for AB tests
As a Data Analyst, I made many reports using different BI instruments (Tableau, SuperSet, Power BI), do analytics over there
As a manager, I managed several people for a several months. I did 1 to 1, I helped them in mastering in our team (Kanban, Agile etc)

**Data Engineer / Machine learning engineer**           
TatraDev | 2020 September - 2021 June           
As a data engineer, I work with backend service of our main machine learning model. I worked with data using mongodb, dvc As a machine learning engineer, I helped with developing of recommendation system, refactoring updating, checking
As a data analyst, I analysed many different data from customer and processing to our source

## Education
GUP | 2020 - 2024             
Bachelor of Informatics             
HSE | 2024 - present             
Master of computer science   

## About

I am a passionate Data Engineer dedicated to continuous learning and professional growth. I thrive on exploring new technologies and methodologies that enhance my skills and expertise in data engineering and analytics. Attending professional conferences is a cornerstone of my development, as these events provide invaluable opportunities to connect with industry leaders, gain insights into emerging trends, and exchange ideas with fellow professionals.

In addition to learning from others, I believe in the importance of giving back to the community. I actively seek opportunities to teach and share knowledge, whether through workshops, mentorship programs, or speaking engagements at conferences. By fostering a culture of collaboration and knowledge-sharing, I aim to empower others in their professional journeys while reinforcing my own understanding of complex concepts.

My commitment to lifelong learning and teaching not only enriches my career but also contributes to the growth and innovation within the data engineering field. I am excited about the future and look forward to continuing this journey of exploration and knowledge-sharing with others.

## Pet-projects

**1. KrishaKZ Parser**              
[Link](https://github.com/K7chyp/krishakz)

One of my most exciting pet projects is the development of a parser for Krishakz, which is a platform for real estate listings. The goal of this project was to extract valuable data from the website, transform it into a structured format, and store it in a PostgreSQL database for further analysis.

**Key Features:**

• **Data Extraction:** I implemented web scraping techniques using libraries like Beautiful Soup and Scrapy to gather data from various listings on the Krishakz platform. This includes details such as property type, price, location, and descriptions.

• **Data Transformation:** After extracting the data, I transformed it into a structured format suitable for database storage. This involved cleaning the data, handling missing values, and ensuring consistency.

• **PostgreSQL Integration:** I designed a PostgreSQL schema to store the parsed data efficiently. This included creating tables for properties, locations, and user interactions, allowing for complex queries and analysis.

• **Automation with Airflow:** To ensure that the data extraction process runs regularly and automatically, I set up cron jobs in Apache Airflow. This allows me to schedule the parser to run at specified intervals, ensuring that the database is always up-to-date with the latest listings.

**Challenges and Learnings:**

• One of the main challenges was dealing with changes in the website's structure, which required me to frequently update the parsing logic.

• I learned about the importance of error handling and logging in data pipelines to track failures and debug issues effectively.

**2. NLP Models for Text Analysis**              
[Link](https://github.com/K7chyp/DostoevskyDoesntWriteIt)

Another fascinating project I undertook involved developing natural language processing (NLP) models to analyze texts, specifically focusing on the works of Fyodor Dostoevsky. The aim was to uncover insights into his writing style, themes, and character development through various analytical techniques.

**Key Features:**

• **Text Preprocessing:** I began by preprocessing the texts, which included tokenization, lemmatization, and removing stop words. This step was crucial for preparing the data for analysis.

• **Model Development:** I experimented with different NLP models, including traditional methods like TF-IDF and more advanced approaches using transformer-based models like BERT. These models helped me analyze sentiment, identify key themes, and even generate summaries of Dostoevsky's works.

• **Visualization:** To present my findings, I created visualizations using libraries like Matplotlib and Seaborn. These visualizations helped illustrate trends in sentiment over time or highlight recurring themes across different novels.

**3. Solve leetcode tasks**                  
[Link](https://github.com/K7chyp/leetcode)


